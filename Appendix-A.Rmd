```{=html}
<style type="text/css">
details:hover { cursor: pointer }
</style>
```
---
author: "Benjamin Meyer, Kenai Watershed Forum"
date: "`r Sys.Date()`"
output: html_document:
  code_folding: hide
---

# (APPENDIX) Appendix {.unnumbered}

# Appendix: Data Uplift to EPA WQX

## Introduction

Prior to analysis and interpretation of water quality data, we will ensure that all data that meets QA/QC standards outlined in the project Quality Assurance Project Plan (QAPP) [@kenaiwatershedforum2020] is accessible in the appropriate repository. Water quality data for this project is ultimately destined for the EPA Water Quality Exchange (EPA WQX), formerly EPA STORET.

Section B10 of the 2020 QAPP describes data management details and responsible parties for each step of the data pipeline from observation to repository.

### 2021 Water Quality Data

Water quality data generated from the Kenai River Baseline Water Quality Monitoring (KRBWQM) program was submitted to the Soldotna office of the Alaska Department of Environmental Conservation (ADEC) in January 2022 using the project-specific AQWMS Template provided by ADEC.



#### 2021 Water Quality Data AQWMS Formatting

The code scripts below assembles water quality data from the three analytical laboratories that partnered with Kenai Watershed Forum for this project in 2021:

-   SGS Laboratories (Anchorage, AK)

-   Soldotna Wastewater Treatment Plant (Soldotna, AK)

-   Taurianen Engineering (Soldotna, AK)

<br>

***


##### Metals/Nutrients Lab Results (SGS Labs)

```{r, echo = F}
xfun::embed_file('other/input/2021_wqx_data/spring_2021_wqx_data/SGS/Spring 2021 Results from SGS.pdf', text = "Download Original 2021 Metals/Nutrients Lab Results from SGS.pdf")

```


<details>

<summary>

*Show/Hide Code used to Prepare 2021 Metals/Nutrients Results*

</summary>


```{r, 2021 AQWMS formatting for SGS}

# clear environment
rm(list=ls())

# load packages
library(tidyverse)
library(readxl)
library(openxlsx)
library(data.table)
library(stringr)
library(magrittr)
library(janitor)
library(hms)
library(lubridate)
library(anytime)

xfun::pkg_load2(c("htmltools", "mime"))


# Assign 2021 Field Sample Dates 

# Spring 2021 sampling date
spring21_sample_date <- "5/11/2021"

# Summer 2021 Sampling Date
summer21_sample_date <-"8/27/2021"

################################################################################################################
######################################### Read in  and Clean SGS/ALS Data ######################################
################################################################################################################


############################ Part A: SGS Data Read In #############################

## Reformat SGS data downloaded from their server client (SGS Engage) to match AQWMS template

### spring 2021 SGS data

#### read in results downloaded from SGS 
spring_sgs21 <- read_excel("other/input/2021_wqx_data/spring_2021_wqx_data/SGS/Spring 2021 Results from SGS.xlsx", sheet = "Report", skip = 4) %>%
  mutate(`Lab Sample` = as.double(`Lab Sample`)) %>%
  # assign field sample date
  mutate(sample_date = spring21_sample_date) %>%
  clean_names()

### summer 2021 SGS data

#### read in results downloaded from SGS 
summer_sgs21 <- read_excel("other/input/2021_wqx_data/summer_2021_wqx_data/SGS/SGS_results_Summer2021.xlsx", sheet = "Report", skip = 4) %>%
  # filter out extraneous info
  filter(!`Client Sample` %in%c("Sample Comments","Client Sample Id"),
         !`Matrix` %in% "200.7 Total Ca, Fe, Mg were analyzed by ALS of Kelso, WA.",
         !is.na(`Lab Sample`)) %>%
  # remove blank columns
  select(-starts_with("...")) %>%
  # assign field sample date
  mutate(sample_date = summer21_sample_date) %>%
  clean_names()

# transform column types to prep for join
summer_sgs21 %<>%
  mutate(lab_sample = as.double(lab_sample),
         reporting_limit = as.double(reporting_limit))

# append spring and summer 2021 results
sgs21 <- bind_rows(spring_sgs21,summer_sgs21) %>%
  # add lab name
  mutate(lab_name = "SGS North America, Anchorage, Alaska") %>%
  # make lab sample column character
  transform(lab_sample = as.character(lab_sample))

rm(spring_sgs21,summer_sgs21)



# Original SGS engage downloads did not contain lab batch info (grey boxes in PDF doc). Acquired upon request in Feb 2022. 
# We need to join batch info to overall results

# read in
spring_batch_sgs21 <- read.csv("other/input/2021_wqx_data/spring_2021_wqx_data/SGS/spring_2021_sgs_batch_info.csv")
summer_batch_sgs21 <- read.csv("other/input/2021_wqx_data/summer_2021_wqx_data/SGS/summer_2021_sgs_batch_info.csv")

# clean up and retain only useful columns
batch_sgs21 <- bind_rows(spring_batch_sgs21,summer_batch_sgs21) %>%
  clean_names() %>%
  remove_empty() %>%
  filter(str_detect(project_id,"Kenai")) %>%
  select(sample_id,
         collect_date,
         lab_sample_id,
         rec_date,
         run_date_time,
         extracted_date,
         analyte,
         analyst, 
         extraction_code,
         dl,
         amount_spiked,
         percent_recovered,
         allowable_limit,
         sample_rpd) %>%
  rename(client_sample = sample_id,
         lab_sample = lab_sample_id,
         detection_limit = dl) %>%
  transform(lab_sample = as.character(lab_sample))

sgs21 <- left_join(batch_sgs21,sgs21, by = c("client_sample","analyte","lab_sample"))




###################### Part B: ALS Data Read In #############################

## SGS subcontracted analyses of Ca, Fe, and Mg to ALS laboratories (Kelso, WA). These results are not included in the spreadsheet download from SGS engage and were entered manually in to seperate spring and summer "ALS" named spreadsheets

# 2/24/2022 - receiving EDD (electronic data deliverables) from ALS. Try it out with spring 2021

#### read in spring 2021 results from ALS 
spring_als21 <- read.csv("other/input/2021_wqx_data/spring_2021_wqx_data/SGS/spring_2021_als_batch_info.csv") %>%
  
  # when summer 2021 results are received, bind/join them here
  
  clean_names() %>%
  remove_empty() %>%
  
  # proceed left to right of existing dataframe to make its naming structure match the sgs21 dataframe
  rename(client_sample = sample,
         collect_date = date_collected,
         lab_sample = lab_code,
         rec_date = date_received,
         # sample_type ::: not sure where to match with sgs data yet or where to put in aqwms, but is important for qa/qc
         extracted_date = date_extracted,
         extraction_code = extraction_method,
         
        ##### SGS data has date and time, ALS has date only. will need to adjust later
        
         run_time_date = date_analyzed,
         analysis = method,
         analyte = component,

        # note: in ALS data, result and result notes (U,J,etc) are already segregated, in SGS data they are not. remedy this.
         qualifier = result_notes,
         amount_spiked = spike_concentration,
         percent_recovered = percent_recovery,
         allowable_limit = acceptance_limits,
         sample_rpd = rpd) %>%
  mutate(matrix = "Water (Surface, Eff., Ground)") 







############## remove below if EDD makes manually entered files unnecessary ##########################

#### read in spring 2021 results from ALS 
spring_als21 <- read_excel("other/input/2021_wqx_data/spring_2021_wqx_data/SGS/Spring 2021 Total Metals from ALS Lab.xlsx", skip = 5) %>%
  # assign field sample date
  mutate(sample_date = spring21_sample_date) %>%
  clean_names()

#### read in summer 2021 results from ALS 
summer_als21 <- read_excel("other/input/2021_wqx_data/summer_2021_wqx_data/SGS/ALS_Data_Results_Summer_2021.xlsx", skip = 5) %>%
  # assign field sample date
  mutate(sample_date = summer21_sample_date) %>%
  clean_names()

# join spring and summer 2021 datasets
als21 <- bind_rows(spring_als21,summer_als21)

# remove old dataframes
rm(spring_als21,summer_als21)

# prep ALS data to be joined with SGS data
als21 %<>%
  rename(client_sample = client_id,
         lab_sample = lab_id,
         reporting_limit = mrl,
         analysis = method) %>%
  select(-qc1,-data_entry,-qc2) %>%
  # transform column types as needed for join in next step
  transform(lab_sample = as.character(lab_sample),
            analysis = as.character(analysis),
            result = as.character(result)) %>%
  # add lab name
  mutate(lab_name = "ALS Environmental - Kelso Laboratory",
         # assign matric type
         matrix = "Water (Surface, Eff., Ground)")

############## remove above if EDD makes manually entered files unnecessary ##########################


# before proceeding here, we want to see if we can acquire other associated 2021 data regarding ALS samples

```



```{r}
# join SGS data with ALS data
sgs21 <- bind_rows(sgs21,als21) 

rm(als21)







############### Part C: Address spelling/format issues and inconsistent sample/site names ######################

# upon visual inspection, we can see that the location names in the AQWMS template differ slightly from the place names in the SGS report (spelling and name inconsistencies).

  
# move info about duplicate sample and/or sample blank status into separate column
sgs21 %<>%
  mutate(sample_condition = case_when(
    grepl("Blank",client_sample) ~ "Blank",
    grepl("DUP",client_sample) ~ "DUP")) %>%
  # remove "DUP" designation from client_sample column
  mutate(client_sample = str_replace(client_sample, "DUP", "")) 

  
# remove from "client_sample" names the text containing the suffixes Diss/Dis (Dissolved metals sample) since we only want a list of unique sites. (Solution for this step found at https://stackoverflow.com/questions/29271549/replace-all-occurrences-of-a-string-in-a-data-frame)
sgs21 %<>%  
  mutate(client_sample = (str_replace(client_sample, "Diss|Dis|DUP", ""))) %>%
  
  # remove "Diss" suffix and "EP" prefix from "analysis" column
  mutate(analysis = str_replace(analysis, "Diss", "")) %>%
  # note trailing space after "EP200.8 "
  mutate(analysis = str_replace(analysis,"EP200.8 ","200.8")) %>%

  # address the one stubborn site name still containing "Diss"
  mutate(client_sample = case_when(
    client_sample == "RM0-No Name Creek  Diss" ~ "RM0-No Name Creek",
    TRUE ~ client_sample)) 
  
  
# We need to remove white spaces, apostrophes, and dashes. Join functions such as "left_join" are often uncooperative with these types of strings
  
sgs21 %<>%
    # remove excess white spaces
  mutate(client_sample = str_trim(client_sample,"both")) %>%
  mutate(client_sample = str_squish(client_sample)) %>%
  
  # make remaining white spaces underscores
  mutate(client_sample = gsub("\\s+","_",client_sample)) %>%
  
  # remove apostrophes
  mutate(client_sample = gsub("\\'","",client_sample)) %>%
  
  # replace dashes with underscores
  mutate(client_sample = gsub("\\-","_",client_sample)) %>%
  
  # replace multiple underscores with single
  mutate(client_sample = gsub("\\__","_",client_sample)) %>%
  mutate(client_sample = gsub("\\___","_",client_sample))

# apply note regarding trip blanks (for BTEX organics)
# assigned in sequence as encountered on chain of custody
sgs21 %<>%
  mutate(note = case_when(
    grepl("Trip_Blank_1", client_sample) ~ "KWF Crew, RM1.5_Kenai_City_Dock",
    grepl("Trip_Blank_2", client_sample) ~ "USFWS Crew, RM6.5_Cunningham_Park",
    grepl("Trip_Blank_3", client_sample) ~ "DEC Crew, RM40_Bings_Landing",
    grepl("Trip_Blank_4", client_sample) ~ "DEC Crew, RM43_Upstream_of_Dow_Island"))
  
  
# seperate result qualifiers (U, J, B) in to a new column
sgs21 %<>%
  mutate(qualifier = str_extract(result,"[aA-zZ]+")) %>%
  mutate(result = str_remove(result,"[aA-zZ]+")) %>%
  
  # again replace multiple underscores with single
  mutate(client_sample = gsub("\\__","_",client_sample)) 







############## Part D: Prepare SGS/ALS Location/Site Names ##########################

# In preparation for a join to AQWMS table, we will manually generate a match table csv file that we can use 

## generate list of unique site names from 2021 SGS data
sgs21_sitenames <- data.table(unique(sgs21$client_sample)) 
  

# generate list of unique site names from 2021 AQWMS template
aqwms21_sitenames <- read_excel("other/input/AQWMS/AWQMS_KWF_Baseline_2021.xlsx", sheet = "Monitoring Locations") %>%
  select("Monitoring Location Name", "Monitoring Location ID") %>%
  distinct()

# write 2021 sgs site names to an excel file
site_match_table_path <- "other/input/AQWMS/sgs_site_names_matching_table.xlsx"
write.xlsx(sgs21_sitenames, site_match_table_path) 

# create an excel file with two sheets: a.) SGS site names, and b.) AQWMS site names
wb <- loadWorkbook(site_match_table_path)
addWorksheet(wb,"Sheet2")
writeData(wb,"Sheet2",aqwms21_sitenames)
saveWorkbook(wb,site_match_table_path,overwrite = TRUE)


# Using these two tables, we will manually create a new file titled "sgs_site_names_matching_table_manual_edit.xlsx" and manually match up the two disparate naming systems. Performed by B Meyer January 2022. 


# append "Monitoring Location Name" and "Monitoring Location ID" info from WQX to spring 2021 SGS data

## read in site names join table
sitenames21_match <- read_excel("other/input/AQWMS/sgs_site_names_matching_table_manual_edit.xlsx") %>%
  select(`Monitoring Location Name`,`Monitoring Location ID`,sgs_sitenames) %>%
  rename(client_sample = sgs_sitenames)

# append monitoring location names
sgs21 %<>%
  left_join(sitenames21_match, by = "client_sample") %>%
  clean_names() 

# remove dfs
rm(sgs21_sitenames,aqwms21_sitenames)

# remove old "client_sample"column
sgs21 %<>% select(-client_sample)






######################## Part E: "Result Analytical Method Context" name rectification ######################

# In the AQWMS template, the EPA names that will go in the column "Result Analytical Method ID" do not exactly match the names provided by the laboratory (SGS). After communicating with SGS on 2/8/2022, we are able to cross-walk between the two naming systems. These matches are documented in the excel file "analysis_code_matching_table.xlsx."

# assign "Result Analytical Method ID" and "Result Analytical Method Context" to dataset using matching table

# read in matching table
analysis_code_matching_table <- read_excel("other/input/AQWMS/analysis_code_matching_table.xlsx") %>%
  select(-Comments,-`EPA Name`) %>%
  clean_names() %>%
  rename(analysis = sgs_analysis_code) %>%
  # remove "EP" prefix from method "EP200.8"
  mutate(analysis = str_replace(analysis,"EP200.8","200.8"))
  

# read in AQWMS Analytical Methods list
aqwms_analytical_methods <- read_excel("other/input/AQWMS/AWQMS_KWF_Baseline_2021.xlsx", sheet = "Analytical Methods") %>%
  select("ID","Context Code") %>%
  clean_names() %>%
  rename(epa_analysis_id = id) 

# join two tables above
epa_analysis_codes <- inner_join(aqwms_analytical_methods,analysis_code_matching_table, by = "epa_analysis_id") %>%
  filter(!context_code %in% c("USEPA Rev 5.4",
                              "APHA (1997)",
                              "APHA (1999)")) 

# join EPA analysis IDs and context codes to overall dataset
sgs21 %<>%
  left_join(epa_analysis_codes, by = "analysis")


rm(analysis_code_matching_table,aqwms_analytical_methods,epa_analysis_codes)



######################## Part F: Assign lab analysis in/out dates ######################

# TBD if necessary
# yes


########################## Miscellaneous Steps #########################################

# rectify select colum classes

sgs21 %<>%
  transform(sample_date = mdy(sample_date))
```

</details>

<br>

***

##### Fecal Coliform Lab Results (Soldotna Wastewater Treatment Plant (SWWTP)/Taurianen Engineering)


```{r, echo = F}
xfun::embed_file('other/input/2021_wqx_data/spring_2021_wqx_data/SWWTP/KRWF Fecal 05-11-21.xls', text = "Download Original Spring 2021 Fecal Coliform Lab Results from SWWTP")

```

```{r, echo = F}
xfun::embed_file('other/input/2021_wqx_data/summer_2021_wqx_data/Taurianen/FecalColiform_Results_Summer2021.pdf', text = "Download Original Summer 2021 Fecal Coliform Lab Results from Taurianen")

```

<details>

<summary>

*Show/Hide Code used to Prepare 2021 Fecal Coliform Results* 

</summary>


```{r}

############################################################################################################
##################################### Read in  and Clean SWWTP / Taurianen FC Data #########################
############################################################################################################

########################### Part A: SWWTP FC Data Read In ##################################################
swwtp_spring21 <- read_excel("other/input/2021_wqx_data/spring_2021_wqx_data/SWWTP/KRWF Fecal 05-11-21.xls", skip = 11) %>%
  clean_names() %>%

## fix site naming and terminology

# move info about duplicate sample and/or sample blank status into separate column
  mutate(sample_condition = case_when(
    grepl("BLANK",sample_location_rm) ~ "Lab Blank",
    grepl("DUP",sample_location_rm) ~ "DUP",
    grepl("POSITIVE",sample_location_rm) ~ "Positive Control")) %>%
  # remove "BLANK", and "POSITIVE designation from sample_location column
  mutate(sample_location_rm = (str_replace(sample_location_rm, "BLANK|POSITIVE", ""))) 

# remove "DUP" from site name column and trim white spaces in site name column
swwtp_spring21 %<>%
  mutate(sample_location_rm = str_remove(sample_location_rm,"DUP")) %>%
  mutate(sample_location_rm = str_trim(sample_location_rm,"right"))


# address different site naming systems
# use manually generated matching table
# read in matching table and match
swwtp_spring21_site_matching <- read_excel("other/input/AQWMS/swwtp_site_names_matching_table_manual_edit.xlsx") 

# join
swwtp_spring21 %<>%  
  full_join(swwtp_spring21_site_matching) %>%
  select(-sample_location_rm)

rm(swwtp_spring21_site_matching)


## fix lab analysis times and dates
swwtp_spring21 %<>%
  # lab processing time/date
  mutate(analysis_time_in = as_hms(time_in),
         analysis_date_in = mdy(spring21_sample_date),
         analysis_time_out = as_hms(time_out),
         # see file "other/input/2021_wqx_data/spring_2021_wqx_data/SWWTP/KRWF Fecal 05-11-21.xls for out analysis date
         analysis_date_out = ymd("2021-05-12")) %>%
  select(-time_in,-time_out) %>%
  transform(time_sampled = as_hms(time_sampled)) %>%
  # field sample date and time
  mutate(time_sampled = as_hms(time_sampled), 
         sample_date = mdy(spring21_sample_date))
  


## rename existing column names and create new ones to match sgs21 data format at end of prior code chunk
swwtp_spring21 %<>% 
  rename(lab_sample = dish_number,
         result = colony_count_100m_l) %>%
  mutate(note = paste0("Lab analysis volume = ",ml," mL"),
         matrix = "Water (Surface, Eff., Ground)",
         analysis = "9222 D ~ Membrane filtration test for fecal coliforms",
         analyte = "Fecal Coliform",
         unit = "cfu/100ml",
         # reporting limit value from 2019 QAPP, pg 17
         reporting_limit = 1.0,
         lab_name = "Soldotna Wastewater Treatment Plant",
         mdl = "",
         note = "",
         qualifier = "",
         epa_analysis_id = "9222D",
         context_code = "APHA",
         analyst = "AW") %>%
  clean_names() %>%
  select(-ml,-colony_count) %>%
  # transform to prep for bind with sgs21
  transform(lab_sample = as.character(lab_sample),
            mdl = as.double(mdl))



## join SGS 2021 data to Spring 2021 Fecal Coliform data from SWWTP
dat <- bind_rows(sgs21,swwtp_spring21)

rm(swwtp_spring21)





########################### Part B: Taurianen FC Data Read In (Summer 2021) ##############################################

## read in taurianen summer 2021 results
taur_summer21 <- read_excel("other/input/2021_wqx_data/summer_2021_wqx_data/Taurianen/Fecal_Coliform_Results_Spreadsheet.xlsx", skip = 3) %>%
  clean_names() %>%
  select(-qc1,-data_entry,-qc2) %>%
  
## move info about duplicate sample and/or sample blank status into separate column
  mutate(sample_condition = case_when(
    grepl("DUP",sample_location) ~ "DUP")) %>%
  # remove "DUP" designation from sample_location column
  mutate(sample_location = (str_replace(sample_location, "_DUP", ""))) %>%
  # trim white spaces in site name column
  mutate(sample_location = str_trim(sample_location,"right")) %>%
  
## add known info about times/dates, correct formats and column names
  mutate(sample_date = mdy(summer21_sample_date),
         analysis_date_in = mdy(summer21_sample_date),
         analysis_time_in = as_hms(time_relinquished),
         analysis_date_out = mdy("8/28/2021"),
         analysis_time_out = as_hms(time_tested), 
         sample_date = mdy(summer21_sample_date),
         # drop old columns
         .keep = "unused") %>%
  select(-date_of_testing) %>%
  transform(time_sampled = as_hms(time_sampled)) %>%
  
## add lab name
  mutate(lab_name = "Taurianen Engineering")
  

## fix site naming and terminology

# generate spreadsheet of unique site names from taurianen dataset 
taur_summer21_sites <- data.frame(unique(taur_summer21$sample_location)) %>%
  rename(sample_location = unique.taur_summer21.sample_location.)

# export site names list to spreadsheet
write.xlsx(taur_summer21_sites, "other/input/AQWMS/taurianen_site_names_matching_table.xlsx")

# manually edit a new spreadsheet such that taurianen site names are paired iwth AWQMS site names
# read in manually edited site names sheet
taur_summer21_sites <- read_excel("other/input/AQWMS/taurianen_site_names_matching_table_manual_edit.xlsx") 

# join AWQMS site names to taurianen data
# taur_summer21 <- left_join(taur_summer21,sitenames21_match,by = "sample_location") 

# here, we are unsuccessful for the join by "sample_location" here for two sites (Poachers and Dow Island) foir unclear reasons. Attempted various fixes to allow left_join to proceed correctly but unsuccessful. 
# temporary work around: export this current stage of dataframe, manually input sites, then re-import dataframe. 

# export
#write.xlsx(taur_summer21,"other/input/AQWMS/taur_summer21_temp.xlsx")

# manually input missing site names

# re-import
taur_summer21 <- read.xlsx("other/input/AQWMS/taur_summer21_temp.xlsx")


## add and/or rename other columns to match SWWTP dataframe structure
taur_summer21 %<>%
  clean_names() %>%
  select(-direct_count,-neg_pos,-sample_location) %>%
  rename(result = number_of_colonies) %>%

  mutate(note = "",
         matrix = "Water (Surface, Eff., Ground)",
         analysis = "9222 D ~ Membrane filtration test for fecal coliforms",
         analyte = "Fecal Coliform", 
         unit = "cfu/100ml",
         reporting_limit = 1,
         mdl = "",
         qualifier = "",
         epa_analysis_id = "922D",
         context_code = "APHA") %>%
  transform(time_sampled = as_hms(time_sampled),
            result = as.character(result),
            analysis_time_in = as_hms(analysis_time_in),
            analysis_time_out = as_hms(analysis_time_out),
            analysis_date_in = excel_numeric_to_date(analysis_date_in),
            analysis_date_out = excel_numeric_to_date(analysis_date_out),
            sample_date = excel_numeric_to_date(sample_date),
            mdl = as.double(mdl))
  

# join 2021 Taurianen Fecal Coliform data into overall dataframe
dat <- bind_rows(dat,taur_summer21)
  

rm(taur_summer21,taur_summer21_sites)

```

</details>

<br>



***

##### Total Dissolved Solids Lab Results (Soldotna Wastewater Treatment Plant (SWWTP))


```{r, echo = F}
xfun::embed_file('other/input/2021_wqx_data/spring_2021_wqx_data/SWWTP/KRWF TSS MONITORING 05-11-21.xlsx', text = "Download Original Spring 2021 Total Suspended Solids Results from SWWTP.xlsx")
```

```{r, echo = F}
xfun::embed_file('other/input/2021_wqx_data/summer_2021_wqx_data/SWWTP/KRWF TSS MONITORING 07-28-21.xlsx', text = "Download Original Summer 2021 Total Suspended Solids Results from SWWTP.xlsx")
```


<details>

<summary>

*Show/Hide Code used to Prepare 2021 Total Dissolved Solids Results* 

</summary>


```{r}
# SWWTP Spring 2021 TSS data
## Reformat TSS data to match AQWMS template

# read in
swwtp_tss_spring21 <- read_excel('other/input/2021_wqx_data/spring_2021_wqx_data/SWWTP/KRWF TSS MONITORING 05-11-21.xlsx', skip = 1, sheet = "Updated_Formatting") %>%
  clean_names() %>%
  transform(date_of_analysis = anydate(date_of_analysis)) %>%
  # add info from lab COC
  mutate(rec_date = "2021-05-11 14:00")

swwtp_tss_summer21 <- read_excel('other/input/2021_wqx_data/summer_2021_wqx_data/SWWTP/KRWF TSS MONITORING 07-28-21.xlsx', skip = 1, sheet = "Updated_Formatting") %>%
  clean_names() %>%
  transform(sample_time = anytime(sample_time)) %>%
  # add info from lab COC
  mutate(rec_date = "2021-07-27 14:00")


# combine spring & summer
swwtp_tss21 <- bind_rows(swwtp_tss_spring21,swwtp_tss_summer21) %>%
  remove_empty() 
rm(swwtp_tss_spring21,swwtp_tss_summer21)

# prepare and format to match larger dataset
swwtp_tss21 %<>%
  # miscellaneous
  select(-qc1,-data_entry,-x8) %>%
  rename(analysis_time = time) %>%
  transform(sample_time = as_hms(sample_time),
            analysis_time = as_hms(analysis_time)) %>%

  # move info about duplicate sample and/or sample blank status into separate column
  mutate(sample_condition = case_when(
    grepl("DUP",sample_location) ~ "DUP")) %>%
  # remove "DUP" designation from locations column
  mutate(sample_location = str_replace(sample_location, "_DUP", "")) %>%
  # replace "O" with zeros in location column
  mutate(sample_location = str_replace(sample_location, "RM_O", "RM_0")) %>%
  # add units of suspended solids
  mutate(unit = "mg/l") %>%
  rename(result = s_s_mg_l) %>%
  transform(result = as.character(result)) %>%
  
  # add info about EPA analysis type from AWQMS template
  mutate(epa_analysis_id = "2540-D",
         analysis = "",
         context_code = "APHA",
         qualifier = "",
         note = "") %>%
  
  # remove tare and paper weight values
  select(-dried_wt,-paper_wt,-tare_wt_kg, -ml) %>%
  
  # modify date/time formats
  mutate(collect_date = as.character(paste(field_sample_date,sample_time)),
         run_date_time = as.character(paste(date_of_analysis,analysis_time)), .keep = "unused",
         # no extractions performed for TSS
         extracted_date = "") %>%
  mutate(sample_date = ymd(collect_date)) %>%
  
  # rename
  rename(analyst = signature) %>%
  
  # miscellaneous
  mutate(lab_sample = "",
         matrix = "Water (Surface, Eff., Ground)",
         analyte = "Total suspended solids",
         reporting_limit = 1.0,
         mdl = as.double(""),
         lab_name = "Soldotna Wastewater Treatment Plant, Soldotna, Alaska")

  
  
# get site names consistent with AWQMS format
swwtp_tss_sitenames <- data.frame(unique(swwtp_tss21$sample_location))

# delete existing csv if present
unlink("other/input/AQWMS/swwtp_tss_sitenames.csv")

# export csv of swwtp_tss site names
write.csv(swwtp_tss_sitenames,"other/input/AQWMS/swwtp_tss_sitenames.csv",row.names = F)

# use this list to create manually edited file, matched to AWQMS template names
# read in manually edited file
swwtp_tss_sitenames <- read_excel("other/input/AQWMS/swwtp_tss_site_names_matching_table_manual_edit.xlsx")

# join correct site names to overall 2021 TSS dataset
swwtp_tss21 <- left_join(swwtp_tss21,swwtp_tss_sitenames)  %>%
  select(-sample_location) %>%
  clean_names()


# join TSS data with overall dataset
z <- bind_rows(dat,swwtp_tss21)

```

</details>


Notes:
- we have lab duplicates from ALS and others... need to retain for internal qa/qc but not submit to aqwms

2/24/22 -- all we are missing for 2021 is the EDD file for summer ALS data. Integrate in pipeline when available. Good to proceed with final formatting!




```{r, eval = F, echo = F}
# remove "client sample"


# create column structure from example in AQWMS template. Use existing input from SGS results if applicable, specify value from "Permitted Values" tab if SGS input not applicable or not yet specified

z <- sgs21 %>%
  # Proceeding left to right across columns of AWQMS template
  # Mutate new column or rename existing column as needed
  
  rename(`Monitoring Location ID` = "monitoring_location_id") %>%
  mutate(
    `Activity Media Name` = "Water",
    `Activity Media Subdivision Name` = "Surface Water",
    # create activity ID name conditionally if condition(s) present
    `Activity ID` = case_when(
      is.na(sample_condition) ~ paste0(monitoring_location_id,"-",sample_date,"-",analyte),
      !is.na(sample_condition) ~ paste0(monitoring_location_id,"-",sample_date,"-",analyte,"-",sample_condition)),
    `Activity ID` = ifelse(is.na(sample_condition),`Activity ID`, paste0(`Activity ID`,"-",sample_condition)),
    #`Activity Start Date` = "*",
    #`Activity Start Time` = "*",
    #`Activity End Date` = "*",
    #`Activity End Time` = "*",
    #`Activity Latitude` = "*",
    #`Activity Longitude` = "*",
    #`Activity Source Map Scale` = "*",
    `Activity Type` = case_when(
      sample_condition == "DUP" ~ "Quality Control Field Replicate Msr/Obs",
      sample_condition == "Blank" ~ "Quality Control Sample-Trip Blank",
      TRUE ~ "Field Msr/Obs"),
    # All samples are surface grab samples. Depths are assigned across the board here as 6 inches (~15 cm) 
    `Activity Depth/Height Measure` = 15,
    `Activity Depth/Height Unit` = "cm",
    # Next three column not applicable for surface grab samples
    `Activity Bottom Depth/Height Measure` = "",
    `Activity Bottom Depth/Height Unit` = "",
    `Activity Relative Depth Name` = "",
    #`Activity Comment` = rename "note
    #`Characteristic Name` = rename "analyte"
    #`Result Analytical Method ID` = rename "epa_analysis_id"
    #`Result Analytical Method Context` = rename "context_code"
    #`Method Speciation` = *
    #`Result Value` =  rename "result"
    #`Result Unit` = rename "unit"
    #`Result Qualifier` = rename "qualifier"
    `Result Weight Basis` = "Sampled",
    `Statistical Base Code` = "",
    #`Result Sample Fraction` = need to assign based on sample collection type
    #`Result Value Type` = do actual in most cases, ask DEC about preference for blank correction
    #`Result Comment` = ""
    `Sample Collection Method ID` = "",
    `Equipment ID` = "Water Bottle",
    #`Result Detection Condition` = assign based on result qualifiers
    #`Result Detection Limit Type` = 
    #`Result Detection Limit Value` = 
    #`Result Detection Limit Unit` = 
    #`Result Detection Limit Type` = 
    #`Result Detection Limit Value` = 
    #`Result Detection Limit Unit` = 
    #`Laboratory Accreditation Indicator` = 
    #`Laboratory Name` = rename
    #`Laboratory Sample ID` = 
    #`Analysis Start Date` = 
    #`Analysis Start Time` = 
    #`Biological Intent` = 
    #`Subject Taxonomic Name` =
    #`Thermal Preservative` = 
    #`Sample Container Type` = 
    #`Sample Container Color` = 
    #`Chemical Preservative` = 

    )
  # rename cols already present
  
   

    

# get all column names from AQWMS template
aqwms_colnames <- read_excel("other/input/AQWMS/AWQMS_KWF_Baseline_2021.xlsx", sheet = "KWF Baseline AWQMS Template") %>%
  names() %>%
  data.frame()

# reorder columns using read in list from aqwms template



```

```{r, eval = F, echo = F}
# check out example from other WQP download
z1 <- read.csv("other/input/wqp_data/narrowresult.csv") %>%
  #filter(CharacteristicName == "Fecal Coliform")
  select(ActivityStartDate,CharacteristicName) %>%
  clean_names() %>%
  transform(activity_start_date = ymd(activity_start_date)) %>%
  group_by(characteristic_name) %>%
  summarise(min_date = min(activity_start_date),
            max_date = max(activity_start_date))

### 1st step:::: make sure that monitoring list locations matches those currently match those in DEC AQWMS database (AWQMS public login: https://awqms2.goldsystems.com/Login.aspx, username akpublic, no password)






```





```{r, notes, include = F}

# course of action

# uplift 2021 data

# audit existing data in WQX

# confirm with DEC that they are addressing data 2017 - 2020

# attempt to download missing data from  AQWMS, then upload to EPA WQX

# if not available, reshape data from shared drive to uplift to EPA WQX (big task)

```

<br>

## 2021 Baseline Water Quality Data

```{r, other notes, include = F}

# ultimately, would like to set up auto query of EPA WQX so this report updates automatically (github actions or other methods...?); eg see front matter guts of https://geocompr.robinlovelace.net/.

```
